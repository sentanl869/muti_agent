#!/usr/bin/env python3
"""
æµ‹è¯•æµå¼è¾“å‡ºè½¬éæµå¼è¾“å‡ºçš„å®ç°
"""

import os
import sys
import unittest
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from config.config import config
from utils.llm_client import LLMClient

class TestStreamImplementation(unittest.TestCase):
    """æµ‹è¯•æµå¼è¾“å‡ºè½¬éæµå¼è¾“å‡ºçš„å®ç°"""
    
    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        # æ£€æŸ¥APIå¯†é’¥
        if not config.llm.api_key:
            self.skipTest("æœªè®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        # æ¢å¤é»˜è®¤é…ç½®
        config.llm.stream = False
    
    def test_non_stream_mode(self):
        """æµ‹è¯•éæµå¼æ¨¡å¼"""
        print("\n=== æµ‹è¯•éæµå¼æ¨¡å¼ ===")
        
        # ç¡®ä¿æµå¼æ¨¡å¼å…³é—­
        config.llm.stream = False
        
        client = LLMClient()
        
        response = client.chat("ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
        
        # éªŒè¯å“åº”
        self.assertIsInstance(response, str)
        self.assertGreater(len(response), 0)
        print(f"éæµå¼å“åº”: {response[:100]}...")
        print("âœ“ éæµå¼æ¨¡å¼æµ‹è¯•æˆåŠŸ")
    
    def test_stream_mode(self):
        """æµ‹è¯•æµå¼æ¨¡å¼"""
        print("\n=== æµ‹è¯•æµå¼æ¨¡å¼ ===")
        
        # å¯ç”¨æµå¼æ¨¡å¼
        config.llm.stream = True
        
        client = LLMClient()
        
        response = client.chat("ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
        
        # éªŒè¯å“åº”
        self.assertIsInstance(response, str)
        self.assertGreater(len(response), 0)
        print(f"æµå¼èšåˆå“åº”: {response[:100]}...")
        print("âœ“ æµå¼æ¨¡å¼æµ‹è¯•æˆåŠŸ")
    
    def test_context_chat_non_stream(self):
        """æµ‹è¯•å¸¦ä¸Šä¸‹æ–‡çš„éæµå¼èŠå¤©"""
        print("\n=== æµ‹è¯•å¸¦ä¸Šä¸‹æ–‡çš„éæµå¼èŠå¤© ===")
        
        # æµ‹è¯•éæµå¼
        config.llm.stream = False
        client = LLMClient()
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹"},
            {"role": "user", "content": "ä½ å¥½"}
        ]
        
        response = client.chat_with_context(messages)
        
        # éªŒè¯å“åº”
        self.assertIsInstance(response, str)
        self.assertGreater(len(response), 0)
        print(f"éæµå¼ä¸Šä¸‹æ–‡å“åº”: {response[:50]}...")
        print("âœ“ éæµå¼ä¸Šä¸‹æ–‡èŠå¤©æµ‹è¯•æˆåŠŸ")
    
    def test_context_chat_stream(self):
        """æµ‹è¯•å¸¦ä¸Šä¸‹æ–‡çš„æµå¼èŠå¤©"""
        print("\n=== æµ‹è¯•å¸¦ä¸Šä¸‹æ–‡çš„æµå¼èŠå¤© ===")
        
        # æµ‹è¯•æµå¼
        config.llm.stream = True
        client = LLMClient()
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹"},
            {"role": "user", "content": "ä½ å¥½"}
        ]
        
        response = client.chat_with_context(messages)
        
        # éªŒè¯å“åº”
        self.assertIsInstance(response, str)
        self.assertGreater(len(response), 0)
        print(f"æµå¼ä¸Šä¸‹æ–‡å“åº”: {response[:50]}...")
        print("âœ“ æµå¼ä¸Šä¸‹æ–‡èŠå¤©æµ‹è¯•æˆåŠŸ")
    
    def test_mode_switching(self):
        """æµ‹è¯•æ¨¡å¼åˆ‡æ¢"""
        print("\n=== æµ‹è¯•æ¨¡å¼åˆ‡æ¢ ===")
        
        client = LLMClient()
        test_prompt = "è¯´ä¸€ä¸ªæ•°å­—"
        
        # æµ‹è¯•éæµå¼
        config.llm.stream = False
        response1 = client.chat(test_prompt)
        
        # æµ‹è¯•æµå¼
        config.llm.stream = True
        response2 = client.chat(test_prompt)
        
        # éªŒè¯ä¸¤ç§æ¨¡å¼éƒ½èƒ½æ­£å¸¸å·¥ä½œ
        self.assertIsInstance(response1, str)
        self.assertIsInstance(response2, str)
        self.assertGreater(len(response1), 0)
        self.assertGreater(len(response2), 0)
        
        print(f"éæµå¼å“åº”: {response1[:30]}...")
        print(f"æµå¼å“åº”: {response2[:30]}...")
        print("âœ“ æ¨¡å¼åˆ‡æ¢æµ‹è¯•æˆåŠŸ")

def run_manual_test():
    """æ‰‹åŠ¨è¿è¡Œæµ‹è¯•çš„å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯•æµå¼è¾“å‡ºè½¬éæµå¼è¾“å‡ºå®ç°...")
    
    # æ£€æŸ¥APIå¯†é’¥
    if not config.llm.api_key:
        print("âš ï¸  è­¦å‘Š: æœªè®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
        print("è¯·åœ¨ PowerShell ä¸­è®¾ç½®ç¯å¢ƒå˜é‡åå†è¿è¡Œæµ‹è¯•:")
        print("$env:DEEPSEEK_API_KEY='your_api_key_here'")
        return
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    suite = unittest.TestLoader().loadTestsFromTestCase(TestStreamImplementation)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # æ€»ç»“ç»“æœ
    print(f"\n=== æµ‹è¯•æ€»ç»“ ===")
    total = result.testsRun
    failures = len(result.failures)
    errors = len(result.errors)
    passed = total - failures - errors
    
    print(f"é€šè¿‡: {passed}/{total}")
    
    if failures == 0 and errors == 0:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æµå¼è¾“å‡ºè½¬éæµå¼è¾“å‡ºå®ç°æˆåŠŸ")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°")
        if failures:
            print(f"å¤±è´¥: {failures}")
        if errors:
            print(f"é”™è¯¯: {errors}")

if __name__ == "__main__":
    run_manual_test()
